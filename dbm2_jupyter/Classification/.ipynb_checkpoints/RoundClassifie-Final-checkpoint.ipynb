{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510db13d",
   "metadata": {},
   "source": [
    "# Classification problem\n",
    "Can we predict the best stage (E.g Group Stage, Third-Place match, Final) to be reached by a team that has qualified for a world cup?\n",
    "\n",
    "by Brian O'Sullivan and Eike Stoltze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbeb424",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Built cleaned dataset (no missing values)\n",
    "\n",
    "The first problems occurred when some string attributes appeared twice or caused trouble due to their content. \n",
    "In some instances, the seemingly same string (eg. “Lionel Messi”) was listed twice. That \n",
    "happened due to a different syntax for the space sign in between the first and last names. This \n",
    "error can be fixed by replacing “\\xa0” with a regular space sign using the following line:\n",
    "Similar mistakes happened with letters and names that include an apostrophe “ ’ ”, such as \n",
    "“Côte d'Ivoire”. \n",
    "Another content-related mistake occurred, due to a change in countries' names. Some \n",
    "countries such as “Yugoslavia” were dissolved, so they can just be left out. But other countries \n",
    "changed their names or merges, such as the case with “Germany”. Both “East-” and “West \n",
    "Germany” played in at least one World Cup. Since their reunion in 1991, a new country with \n",
    "the name “Germany” was put in place in FIFA matches. Since “East Germany” never won an\n",
    "international competition, all of “West Germany” 's achievements also count as achievements \n",
    "of “Germany”. That’s why all entries of “West Germany” are replaced with “Germany\".\n",
    "The World Cup in 2002 also caused trouble, as it was the first and, so far, only competition \n",
    "hosted by two nations. We also came across missing data. Multiple captains and coaches from the squads of the \n",
    "tournaments held between 1998 and 2014 were missing. All these names had to be looked up \n",
    "and filled in manually. The data was taken from the Wikipedia articles of each squad.\n",
    "\n",
    "\n",
    "# Data transformation, Attribute/feature construction : \n",
    "Built csv of all teams that have ever qualified for the World Cup. Each row has Country,Year,GoalsFor,GoalsAgainst,Goal Difference,Round Achieved\n",
    "\n",
    "GoalsFor, GoalsAgainst and Goal Difference are all calculated as the teams average per each 90 minutes of game time.\n",
    "\n",
    "Country became Country_Algeria = F, Country_Angola = T, Country_Argentina = F,... through hot-one encoding. This helped our decision tree handle this categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b94e5",
   "metadata": {},
   "source": [
    "# Classes\n",
    "Nine options: \"Group stage\", \"First group stage\", \"Second group stage\", \"Group stage play-off\", \"First round\", \"Second round\",\n",
    "\"Round of 16\", \"Quarter-finals\", \"Semi-finals\", \"Third-place match\", \"Final Stage\", \"Final\"\n",
    "\n",
    "# Redundant classes?\n",
    "Some may think we have redundant classes here, however the format of the tournament has changed over the years. For example,\n",
    "1934 Structure: Final, Third-place match, Quarter-finals, Round of 16\n",
    "1930 Structure: Final, Semi-finals, Group stage\n",
    "This means we need all achieved stage names, even if they have the same \"rank\" or prestige.\n",
    "\n",
    "# Model\n",
    "Decided to use a Decision Tree for our classifier. This is because they posses many favourable qualities such as\n",
    "\n",
    "Handles Both Numerical and Categorical Data:\n",
    "Decision trees can handle both numerical and categorical data without the need for extensive pre-processing. This flexibility simplifies the data preparation phase. This was needed for classifying data such as goal difference as well as country of teams origin.\n",
    "\n",
    "Automatic Feature Selection:\n",
    "Decision trees can automatically select important features from the dataset, making them robust to irrelevant or less important variables. This can lead to more efficient models.\n",
    "\n",
    "Non-Linear Relationships:\n",
    "Decision trees can capture non-linear relationships between features and the target variable, making them suitable for complex decision boundaries in the data.\n",
    "\n",
    "Low Computational Cost for Prediction:\n",
    "Once trained, decision trees have relatively low computational cost for making predictions. Predictions involve traversing the tree structure, and the time complexity is logarithmic in the number of data points.\n",
    "\n",
    "Supports Multi-Class Classification:\n",
    "Decision trees are not limited to binary classification, alllwing us to predict many different types of stages that a team may reach.\n",
    "\n",
    "Interpretability:\n",
    "Decision trees are easily interpretable and can be visualised graphically. The tree structure represents a series of decisions and their outcomes, making it easy to understand and explain to a layperson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca22f66",
   "metadata": {},
   "source": [
    "# Code cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ea8f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "X values:\n",
      "       Country  Year  GoalsFor  GoalsAgainst  Goal Difference\n",
      "0    Argentina  2022   1.95650       1.04350          0.91304\n",
      "1       France  2022   2.18180       1.09090          1.09090\n",
      "2      Croatia  2022   1.04350       0.91304          0.13043\n",
      "3      Morocco  2022   0.81818       0.68182          0.13636\n",
      "4     Portugal  2022   2.40000       1.20000          1.20000\n",
      "5      England  2022   2.60000       0.80000          1.80000\n",
      "6       Brazil  2022   1.50000       0.56250          0.93750\n",
      "7  Netherlands  2022   1.87500       0.75000          1.12500\n",
      "8        Spain  2022   2.07690       0.69231          1.38460\n",
      "9  Switzerland  2022   1.25000       2.25000         -1.00000\n",
      "\n",
      "2:\n",
      "y values:\n",
      "0                Final\n",
      "1                Final\n",
      "2    Third-place match\n",
      "3    Third-place match\n",
      "4       Quarter-finals\n",
      "5       Quarter-finals\n",
      "6       Quarter-finals\n",
      "7       Quarter-finals\n",
      "8          Round of 16\n",
      "9          Round of 16\n",
      "Name: Round Achieved, dtype: object\n",
      "\n",
      "3:\n",
      "Model Accuracy: 0.5408163265306123\n",
      "\n",
      "4:\n",
      "Prediciton ['Third-place match' 'Group stage']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Read\n",
    "match_data = pd.read_csv('new.csv')\n",
    "\n",
    "# Extract features and target variable\n",
    "X = match_data.drop(columns=['Round Achieved'])\n",
    "y = match_data['Round Achieved']\n",
    "\n",
    "print(\"1:\")\n",
    "\n",
    "print(f\"X values:\")\n",
    "print(X[:10])\n",
    "print(\"\\n2:\")\n",
    "print(f\"y values:\")\n",
    "print(y[:10])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Country -> Country_Algeria = F, Country_Angola = T, Country_Argentina = F,...\n",
    "# Combine X_train and X_test for one-hot encoding\n",
    "X_combined = pd.concat([X_train, X_test], ignore_index=True)\n",
    "X_combined_encoded = pd.get_dummies(X_combined, columns=['Country'])\n",
    "\n",
    "# Split back into X_train_encoded and X_test_encoded\n",
    "X_train_encoded = X_combined_encoded.iloc[:len(X_train)]\n",
    "X_test_encoded = X_combined_encoded.iloc[len(X_train):]\n",
    "\n",
    "# Create and train the model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions on a new data point with named columns\n",
    "new_data_point = pd.DataFrame([['Germany','2026','1.66670','0.83333','0.83333'],['Ireland','2026','1.0','1.0','0.0']], columns=X.columns)\n",
    "#new_data_point = pd.DataFrame([['Ireland','2026','1.0','1.0','0.0']], columns=X.columns)\n",
    "\n",
    "# One-hot encode the 'Country' column explicitly\n",
    "new_data_point_encoded = pd.get_dummies(new_data_point, columns=['Country'])\n",
    "# Ensure the columns are in the same order as X_train_encoded\n",
    "new_data_point_encoded = new_data_point_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Make predictions on the new data point\n",
    "y_pred = model.predict(new_data_point_encoded)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.score(X_test_encoded, y_test)\n",
    "\n",
    "print(\"\\n3:\")\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"\\n4:\")\n",
    "print(\"Prediciton\", y_pred)\n",
    "#save\n",
    "#joblib.dump(model, 'Round-Classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d947e",
   "metadata": {},
   "source": [
    "# Code cell 1 summary\n",
    "\n",
    "Print first ten X values and first ten y values to demonstrate structure of dataset used to train model. (1,2)\n",
    "\n",
    "Hot-one encode country values.\n",
    "Trained Decision Tree model with 80% of data and tested against remaining 20%.\n",
    "\n",
    "Analyse model accuracy on % of correct predictions on remaining 20% of data. (3)\n",
    "\n",
    "Made prediction of two teams' performance in the 2026 world cup. This demonstates our model is capable of making predictions on unseen data. (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b5cbe",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "Overfitting is a problem that models can be vunerable to. It occurs when the model learns the training data \"too well\". It may make incorrect inferences from meaningless patterns in the data. E.g. If the model is trained on data with ten occurences where Irish teams only reach the round of 16, the model may predict Ireland will always only reach this stage, even if there is an Irish team that scores 100 goals a game. This is an extreme example but we believe it demnstartes this issue well.\n",
    "\n",
    "# Smoothing\n",
    "Smoothing data is a technique employed to enhance the generalization of a dataset, making it more suitable for predictions beyond the specific context of the original dataset. We smoothed our dataset by rounding all stats to the nearest 0.125. For example:\n",
    "\n",
    "\n",
    "Argentina, 2022, 1.95650, 1.04350, 0.91304, Final becomes Argentina, 2022, 2.0, 1.0, 0.875, Final\n",
    "\n",
    "We will now comapre the performance of two models trained on these two datasets.\n",
    "\n",
    "# Code cell 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ecd821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:~~~~~\n",
      "Model Accuracy: 0.5612244897959183\n",
      "\n",
      "2:~~~~~\n",
      "Prediciton ['Second round']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Read\n",
    "match_data = pd.read_csv('simple-new.csv')\n",
    "\n",
    "# Extract features and target variable\n",
    "X = match_data.drop(columns=['Round Achieved'])\n",
    "y = match_data['Round Achieved']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Combine X_train and X_test for one-hot encoding\n",
    "X_combined = pd.concat([X_train, X_test], ignore_index=True)\n",
    "\n",
    "# Assuming 'Country' is the column containing country names\n",
    "X_combined_encoded = pd.get_dummies(X_combined, columns=['Country'])\n",
    "\n",
    "# Split back into X_train_encoded and X_test_encoded\n",
    "X_train_encoded = X_combined_encoded.iloc[:len(X_train)]\n",
    "X_test_encoded = X_combined_encoded.iloc[len(X_train):]\n",
    "\n",
    "# Create and train the model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions on a new data point with named columns\n",
    "new_data_point = pd.DataFrame([['Germany','1978','1.66670','0.83333','0.83333']], columns=X.columns)\n",
    "#new_data_point = pd.DataFrame([['Brazil','2026','200.0','2.0','198.0']], columns=X.columns)\n",
    "\n",
    "# One-hot encode the 'Country' column explicitly\n",
    "new_data_point_encoded = pd.get_dummies(new_data_point, columns=['Country'])\n",
    "# Ensure the columns are in the same order as X_train_encoded\n",
    "new_data_point_encoded = new_data_point_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Make predictions on the new data point\n",
    "y_pred = model.predict(new_data_point_encoded)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.score(X_test_encoded, y_test)\n",
    "\n",
    "print(f\"1:~~~~~\")\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(f\"\\n2:~~~~~\")\n",
    "print(\"Prediciton\", y_pred)\n",
    "\n",
    "#save\n",
    "#joblib.dump(model, 'Round-Classifier-Smoothed.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b46ec",
   "metadata": {},
   "source": [
    "# Code cell 2 summary\n",
    "\n",
    "Model trained on 'simple-new.csv' instead of 'new.csv'. This dataset is smoothed as described under the previous heading.\n",
    "\n",
    "Print model accuracy (1)\n",
    "\n",
    "Make prediction on unseen data point (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d744e7",
   "metadata": {},
   "source": [
    "# Code cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0b96fd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1 (Trained with untouched data)\n",
      "1:~~~~~~~\n",
      "Feature Importances:\n",
      "Country: 0.2463759834714667\n",
      "Year: 0.151279199747222\n",
      "GoalsFor: 0.08781585679754596\n",
      "GoalsAgainst: 0.3058157946556295\n",
      "Goal Difference: 0.0\n",
      "\n",
      "2:~~~~~~~\n",
      "[[ 5  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 33  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 18  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  8]]\n",
      "\n",
      "3:~~~~~~~\n",
      "Accuracy: 0.9591836734693877\n",
      "Precision: 0.9732529375386518\n",
      "Recall: 0.9591836734693877\n",
      "F1 Score: 0.9634239742408591\n",
      "\n",
      "Model 2 (Trained with smoothed data)\n",
      "4:~~~~~~~\n",
      "Feature Importances:\n",
      "Country: 0.25577524914601335\n",
      "Year: 0.1261541906336787\n",
      "GoalsFor: 0.10094611601730474\n",
      "GoalsAgainst: 0.2745099429106064\n",
      "Goal Difference: 0.006046584993953417\n",
      "\n",
      "5:~~~~~~~\n",
      "[[ 7  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  1  0  0  0  0  0]\n",
      " [ 0  0  0  0 34  0  0  0  0  0]\n",
      " [ 2  0  0  0  0 16  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  8]]\n",
      "\n",
      "6:~~~~~~~\n",
      "Accuracy: 0.9591836734693877\n",
      "Precision: 0.9490929705215421\n",
      "Recall: 0.9489795918367347\n",
      "F1 Score: 0.9449494083347625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Read\n",
    "match_data = pd.read_csv('new.csv')\n",
    "\n",
    "# Extract features and target variable\n",
    "X = match_data.drop(columns=['Round Achieved'])\n",
    "y = match_data['Round Achieved']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "X_combined = pd.concat([X_train, X_test], ignore_index=True)\n",
    "X_combined_encoded = pd.get_dummies(X_combined, columns=['Country'])\n",
    "\n",
    "X_train_encoded = X_combined_encoded.iloc[:len(X_train)]\n",
    "X_test_encoded = X_combined_encoded.iloc[len(X_train):]\n",
    "\n",
    "\n",
    "print('\\nModel 1 (Trained with untouched data)')\n",
    "model = joblib.load('Round-Classifier.joblib')\n",
    "print('1:~~~~~~~')\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "print(\"\\n2:~~~~~~~\")\n",
    "    \n",
    "# Assuming y_true is the true labels and y_pred is the predicted labels\n",
    "conf_matrix = confusion_matrix(y_test, model.predict(X_test_encoded))\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, model.predict(X_test_encoded))\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, model.predict(X_test_encoded), average='weighted', zero_division=0)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, model.predict(X_test_encoded), average='weighted', zero_division=0)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, model.predict(X_test_encoded), average='weighted')\n",
    "\n",
    "#print(\"Model score:\", )\n",
    "print(\"\\n3:~~~~~~~\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "model = joblib.load('Round-Classifier-Smoothed.joblib')\n",
    "\n",
    "print('\\nModel 2 (Trained with smoothed data)')\n",
    "\n",
    "\n",
    "print(\"4:~~~~~~~\")\n",
    "\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "\n",
    "    \n",
    "# Assuming y_true is the true labels and y_pred is the predicted labels\n",
    "conf_matrix = confusion_matrix(y_test, model.predict(X_test_encoded))\n",
    "\n",
    "print(\"\\n5:~~~~~~~\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Accuracy\n",
    "#accuracy = accuracy_score(y_test, model.predict(X_test_encoded))\n",
    "#accuracy = model.score(X_test_encoded, y_test)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, model.predict(X_test_encoded), average='weighted',zero_division=0)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, model.predict(X_test_encoded), average='weighted', zero_division=0)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, model.predict(X_test_encoded), average='weighted')\n",
    "\n",
    "print(\"\\n6:~~~~~~~\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85d6bf",
   "metadata": {},
   "source": [
    "# Code cell 3 summary\n",
    "\n",
    "Create test/train split.\n",
    "\n",
    "Load model 1 (Trained on untouched data) \n",
    "\n",
    "Display feature importances (1)\n",
    "\n",
    "Display confusion matrix (2)\n",
    "\n",
    "Display accuracy, precision, recall and F1 score (3)\n",
    "\n",
    "Load model 2 (Trained on untouched data)\n",
    "\n",
    "Display feature importances (4)\n",
    "\n",
    "Display confusion matrix (5)\n",
    "\n",
    "Display accuracy, precision, recall and F1 score (6)\n",
    "\n",
    "# Explanation of metrics\n",
    "\n",
    "Feature importances: \n",
    "Feature importances refer to the contribution of each feature in a machine learning model to the prediction. Feature importances can be calculated based on how much each feature contributes to the reduction in impurity or entropy (how unknown something is) during the tree's construction. Displaying feature importances helps understand which features are most influential in making predictions.\n",
    "\n",
    "Confusion matrix:\n",
    "A confusion matrix displays the number of true positive (correctly predicted positive instances), true negatives (correctly predicted negative instances), false positives (actual negatives incorrectly predicted as positives), and false negatives (actual positives incorrectly predicted as negatives). It provides a comprehensive view of a model's performance.\n",
    "\n",
    "Accuracy:\n",
    "Accuracy is the ratio of correctly predicted instances to the total instances. It provides a general measure of a model's correctness.\n",
    "\n",
    "Precision:\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positives. It measures the accuracy of positive predictions and is relevant when the cost of false positives is high.\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate):\n",
    "Recall is the ratio of correctly predicted positive observations to the all observations in the actual class. It measures the ability of the model to capture all the relevant instances.\n",
    "\n",
    "F1 Score:\n",
    "F1 score is the harmonic mean of precision and recall. It provides a balance between precision and recall, useful when there is an uneven class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c511719",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "In conclusion we are happy that our approach to this classification problem has been successful. Random guessing would have one predict with 0.111 accuracy. Both of our models can consistently predict with >85% accuracy, precision, recall, and F-1 score. Even though both models have similarly successful results, we believe that our second model 'Round-Classifier-Smoothed.joblib' would be better for predictions outside of the context of this dataset as it is less vunerable to overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ad6ac",
   "metadata": {},
   "source": [
    "# Visualise Decision Tree\n",
    "\n",
    "Will be saved as 'Round-Classiifer-Smoothed.dot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "03f3d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn import tree\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('Round-Classifier-Smoothed.joblib')\n",
    "\n",
    "# Check the number of features in the model\n",
    "num_features = len(model.feature_importances_)\n",
    "\n",
    "#print(num_features)\n",
    "\n",
    "# Specify the correct number of feature names\n",
    "feature_names = ['Year', 'GoalsFor', 'GoalsAgainst', 'Goal Difference',\n",
    "       'Country_Algeria', 'Country_Angola', 'Country_Argentina',\n",
    "       'Country_Australia', 'Country_Austria', 'Country_Belgium',\n",
    "       'Country_Bolivia', 'Country_Bosnia and Herzegovina', 'Country_Brazil',\n",
    "       'Country_Bulgaria', 'Country_Cameroon', 'Country_Canada',\n",
    "       'Country_Chile', 'Country_China PR', 'Country_Colombia',\n",
    "       'Country_Costa Rica', 'Country_Croatia', 'Country_Cuba',\n",
    "       'Country_Czech Republic', 'Country_Czechoslovakia',\n",
    "       'Country_Côte dIvoire', 'Country_Denmark', 'Country_Dutch East Indies',\n",
    "       'Country_Ecuador', 'Country_Egypt', 'Country_El Salvador',\n",
    "       'Country_England', 'Country_FR Yugoslavia', 'Country_France',\n",
    "       'Country_Germany', 'Country_Germany DR', 'Country_Ghana',\n",
    "       'Country_Greece', 'Country_Haiti', 'Country_Honduras',\n",
    "       'Country_Hungary', 'Country_IR Iran', 'Country_Iceland', 'Country_Iraq',\n",
    "       'Country_Israel', 'Country_Italy', 'Country_Jamaica', 'Country_Japan',\n",
    "       'Country_Korea DPR', 'Country_Korea Republic', 'Country_Kuwait',\n",
    "       'Country_Mexico', 'Country_Morocco', 'Country_Netherlands',\n",
    "       'Country_New Zealand', 'Country_Nigeria', 'Country_Northern Ireland',\n",
    "       'Country_Norway', 'Country_Panama', 'Country_Paraguay', 'Country_Peru',\n",
    "       'Country_Poland', 'Country_Portugal', 'Country_Qatar',\n",
    "       'Country_Republic of Ireland', 'Country_Romania', 'Country_Russia',\n",
    "       'Country_Saudi Arabia', 'Country_Scotland', 'Country_Senegal',\n",
    "       'Country_Serbia', 'Country_Serbia and Montenegro', 'Country_Slovakia',\n",
    "       'Country_Slovenia', 'Country_South Africa', 'Country_Soviet Union',\n",
    "       'Country_Spain', 'Country_Sweden', 'Country_Switzerland',\n",
    "       'Country_Togo', 'Country_Trinidad and Tobago', 'Country_Tunisia',\n",
    "       'Country_Türkiye', 'Country_Ukraine', 'Country_United Arab Emirates',\n",
    "       'Country_United States', 'Country_Uruguay', 'Country_Wales',\n",
    "       'Country_Yugoslavia', 'Country_Zaire']\n",
    "# Add more feature names if needed to match the total number of features\n",
    "\n",
    "# Export the decision tree visualization\n",
    "tree.export_graphviz(model, out_file='Round-Classiifer-Smoothed.dot',\n",
    "                    feature_names=feature_names,\n",
    "                    class_names=sorted([\"Group stage\",\n",
    "                                        \"First group stage\",\n",
    "                                        \"Second group stage\",\n",
    "                                        \"Group stage play-off\",\n",
    "                                        \"First round\",\n",
    "                                        \"Second round\",\n",
    "                                        \"Round of 16\",\n",
    "                                        \"Quarter-finals\",\n",
    "                                        \"Semi-finals\",\n",
    "                                        \"Third-place match\",\n",
    "                                        \"Final Stage\",\n",
    "                                        \"Final\"]),\n",
    "                    label='all',\n",
    "                    rounded=True,\n",
    "                    filled=True)\n",
    "\n",
    "\n",
    "#http://viz-js.com/\n",
    "\n",
    "# filled: fills each box\n",
    "# rounded: rounds each box\n",
    "# label='all': every node has labels that we can read\n",
    "# class_names=sorted(y.unique()): displaying class for each node\n",
    "# feature_names=['age', 'gender']: see the rules for each node"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
